{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934d96a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c59016",
   "metadata": {},
   "outputs": [],
   "source": [
    "are_you_on_kaggle = False \n",
    "\n",
    "# Load data from kaggle\n",
    "if are_you_on_kaggle: \n",
    "    train = pd.read_csv('/kaggle/input/playground-series-s5e4/train.csv', index_col='id')\n",
    "    test  = pd.read_csv('/kaggle/input/playground-series-s5e4/test.csv', index_col='id')\n",
    "    subm  = pd.read_csv('/kaggle/input/playground-series-s5e4/sample_submission.csv')\n",
    "else: # load data from local\n",
    "    train = pd.read_csv('train.csv',index_col='id')\n",
    "    test  = pd.read_csv('test.csv', index_col='id')\n",
    "    subm  = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3c455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:33<00:00,  2.22s/it]\n",
      "100%|██████████| 15/15 [00:11<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def feature_eng(df,train=True):\n",
    "    le = LabelEncoder() \n",
    "\n",
    "    # New Columns\n",
    "    df['Episode_Title'] = df['Episode_Title'].str.replace('Episode ', '', regex=False).astype('category')\n",
    "    #df['Ad_Density'] = df['Number_of_Ads'] / df['Episode_Length_minutes']\n",
    "    #df['Ad_Density'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "    if train:\n",
    "        # Get rid of outliers\n",
    "        df = df[df['Number_of_Ads']<10]\n",
    "\n",
    "    # Fill NULL values with median\n",
    "    df['Number_of_Ads'].fillna(df['Number_of_Ads'].median(), inplace=True) \n",
    "    df['Guest_Popularity_percentage'].fillna(df['Guest_Popularity_percentage'].median(), inplace=True)\n",
    "    df['Episode_Length_minutes'].fillna(df['Episode_Length_minutes'].median(), inplace=True)\n",
    "    \n",
    "    # Preprocess Categorical Columns\n",
    "    categorical_cols = ['Podcast_Name','Genre','Publication_Day','Publication_Time','Episode_Sentiment']\n",
    "    for c in categorical_cols:\n",
    "        df[c]=le.fit_transform(df[c]) # Converts categorical column into int format\n",
    "        df[c] = df[c].astype('category') # Define column type as category \n",
    "\n",
    "    \n",
    "    # Adding 2 by 2 combinations of categorical cols as columns\n",
    "    gc.collect()\n",
    "    categorical_cols.append('Episode_Title')\n",
    "    pair_size = [2]\n",
    "\n",
    "    for r in pair_size:\n",
    "        for cols in tqdm(list(combinations(categorical_cols, r))):\n",
    "            new_col_name = '_'.join(cols)\n",
    "            \n",
    "            df[new_col_name] = df[list(cols)].astype(str).agg('_'.join, axis=1)\n",
    "            df[new_col_name] = df[new_col_name].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply\n",
    "\n",
    "train = feature_eng(train)\n",
    "test = feature_eng(test,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_data(df):\n",
    "    # Reduce Data sizes\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "        #elif pd.api.types.is_categorical_dtype(df[col]):\n",
    "            #df[col] = df[col].cat.codes.astype('int16')\n",
    "        elif df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "    return df\n",
    "\n",
    "def train_model(params,rounds=5000):\n",
    "    # Train final model on full data\n",
    "    full_dtrain = xgb.DMatrix(X, label=y, enable_categorical=True)\n",
    "    final_model = xgb.train(\n",
    "        params,\n",
    "        full_dtrain,\n",
    "        num_boost_round=rounds,\n",
    "        verbose_eval=250\n",
    "    )\n",
    "    return final_model\n",
    "\n",
    "def create_submission():\n",
    "    test_processed = optimize_data(test)\n",
    "    xgb_test = xgb.DMatrix(test_processed, enable_categorical=True)\n",
    "    test_results = final_model.predict(xgb_test)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"id\": subm[\"id\"],\n",
    "        \"Listening_Time_minutes\": test_results\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_search(X, y, custom_param_range=False, trial_count=10):       \n",
    "    def objective(trial):\n",
    "        if not custom_param_range: # wider search range\n",
    "            params = {\n",
    "                'max_bin': trial.suggest_int('max_bin', 512, 2048),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 1.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 1.0, log=True),\n",
    "            }\n",
    "        else: # For Experiments\n",
    "            params = {\n",
    "                'device': 'cuda',\n",
    "                'max_depth': 15,\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'reg:squarederror',\n",
    "                'max_bin': trial.suggest_int('max_bin', 700, 1600),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.015, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 0.2, 0.35),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 3, 5),\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 0.8),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 0.95),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 0.5, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.3, 0.8, log=True),\n",
    "            }\n",
    "            \n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val, enable_categorical=True)\n",
    "    \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=10000, \n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=50,  \n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        del dtrain, dval\n",
    "        gc.collect()\n",
    "        \n",
    "        return model.best_score\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(n_startup_trials=10),\n",
    "        pruner=optuna.pruners.MedianPruner(\n",
    "            n_warmup_steps=10,\n",
    "            n_min_trials=5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    study.optimize(objective, n_trials=trial_count, show_progress_bar=True)\n",
    "    \n",
    "    return study.best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"Listening_Time_minutes\"]\n",
    "X = optimize_data(train.drop(\"Listening_Time_minutes\", axis=1))\n",
    "\n",
    "result_params = optuna_search(X, y, custom_param_range=True, trial_count=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
